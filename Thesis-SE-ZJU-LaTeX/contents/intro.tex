% !TEX root = ../main.tex

% 第一章一般名为绪论／引言，不可省略

\chapter{绪论}

\section{课题背景与研究意义}

在当前人工智能技术广泛赋能的时代，结构化图数据\cite{图结构数据1,图结构数据2}在多个关键领域中扮演着基础性角色。
社交网络中用户间的关注、互动构成异质社交图，用于社交网络分析\cite{社交网络分析1,社交网络分析2}与推荐系统 \cite{He2020LightGCNSA,Wang2021LearningIB}；
生物医药领域中分子结构与蛋白质交互天然以图形式建模，广泛用于生物网络分析\cite{Guo2022GraphbasedMR,Liu_Wang_Vu_Moretti_Bodenheimer_Meiler_Derr_2023}与分子生成\cite{Hu2020OpenGB}；
交通调度与城市计算将路网与交通流抽象为图模型，用于路径优化与实时控制\cite{Zheng2019GMANAG}；
金融风控利用交易网络进行欺诈检测和信用建模\cite{eFraudCom}；
电子电路与EDA设计中电路拓扑本身即为图结构\cite{DeepGate}。
随着多领域数据规模与复杂性不断增长，图结构在表示复杂实体间多关系、高阶依赖方面展现出不可替代的表达能力。
因此，如何从图结构中高效抽取语义、理解拓扑规律，并迁移到各类图计算任务中，成为当前人工智能研究中的重要课题之一。

传统的图结构计算
主要依赖符号方法\cite{Blondel2008FastUO,随机游走,谱聚类,标签传播,图同构检测}与
统计学习方法\cite{Perozzi2014DeepWalkOL,Grover2016node2vecSF,Tang2015LINELI,高阶邻接嵌入,有向图高阶传递性嵌入}。
符号方法以图论与谱分析为核心，
通过模块度优化\cite{Blondel2008FastUO}、随机游走\cite{随机游走}、谱聚类\cite{谱聚类}、标签传播\cite{标签传播}及图同构检测\cite{图同构检测}等手段揭示图的拓扑规律，具有良好的可解释性，
但在处理大规模、动态与异质图时受限于计算复杂度与人工特征设计。
统计学习方法则通过随机游走\cite{Perozzi2014DeepWalkOL,Grover2016node2vecSF}与矩阵分解\cite{Tang2015LINELI,高阶邻接嵌入,有向图高阶传递性嵌入}等嵌入技术，
将离散图结构映射至连续向量空间，以实现节点、边及子图的低维表征。
然而，这些传统范式普遍存在局部表达受限，在大规模图计算中面临效率与泛化性挑战。

随着图神经网络（GNNs）的发展，图学习领域逐步从传统的机器学习转向深度学习。
然而，过平滑现象（over-smoothing）\cite{Rusch2023ASO}和过压缩问题（over-squashing）\cite{Alon2020OnTB}问题共同限制了 GNNs 在大规模图数据上的表达能力与可扩展性。
为突破这一限制，研究者开始探索以大规模语言模型（如BERT\cite{BERT}, T5\cite{T5}, LLaMA\cite{Llama}）为核心的图结构计算新范式。
该方向旨在将图的结构关系与语义信息统一映射至语言空间，使模型具备跨节点、跨关系的全局推理能力。
依托语言模型卓越的语义理解与生成式推理机制，图数据获得了语义补全、自解释与可迁移的潜能，展现出超越传统图神经网络的泛化能力与知识整合能力。
在这一趋势下，图大语言模型（Graph Large Language Models,Graph-LLMs） 逐渐成为连接符号推理与语义建模的关键桥梁。它们试图让语言模型具备理解、推理并生成图结构信息的能力，从而在统一的语义框架中实现图计算与自然语言处理的融合。

尽管 Graph-LLMs 在图语义理解与推理方面取得初步进展，现有研究仍面临一些技术性挑战和局限性，主要集中在以下几个方面：

\textbf{1）图结构编码存在信息缺失与拓扑保真不足：} 现有做法多依赖邻域采样与简化线性化，将图转换为可读序列或片段式子图。此过程易引入起点与遍历路径偏置，边与连通性被截断或重排，环、桥接与长链路等关键结构难以被完整呈现。随之而来的，是对路径可达性、中心性与全局属性的估计偏差，导致在节点分类、链接预测与结构问答等任务上出现系统性性能下滑。

\textbf{2）表示保真与跨模态对齐不足：} 将图转写为文本后，结构信号被弱化为局部片段，缺乏对多阶邻居与全局依赖的统一刻画；同时，语言模型天然缺少图归纳偏置，图与文本嵌入空间难以实现稳定的一一对应。结果表现为：全局与局部语义映射不一致，节点/边级细粒度语义难以锚定到相应词片，跨样本与跨域的表示漂移加剧，模型对复杂拓扑的理解与迁移显著受限。

\textbf{3）推理建模与泛化能力不足：} 以监督微调为主的训练范式往往学习任务捷径而非通用结构规律，模型多给出“结论式”回答而缺少可核验的中间推理链，导致可解释性与稳健性不足。面对未见任务、异构图或尺度变化时，表现出明显的域外退化：对长距离依赖的判断不稳定，对结构扰动与数据漂移敏感，零样本与小样本条件下的迁移能力有限。

尽管存在上述挑战，近年来深度学习技术的演进，尤其是跨模态表征学习与生成式预训练范式的发展，为图大语言模型的进一步突破奠定了基础。
一方面，多模态融合模型在视觉、语音、文本等领域的成功实践表明，大模型具备强大的跨域语义抽象与表示迁移能力，为图模态与语言模态的统一建模提供了新的范式支撑。
另一方面，图结构序列化编码、对比学习与指令微调等方法的引入，使语言模型能够在结构感知的前提下学习图的拓扑依赖与语义关联，提升模型在复杂图任务中的理解与推理能力。

\section{相关研究工作}

对于国内硕士学位论文来说，
一般较少研究完全无前人探索的领域，
所以有必要交待前人在此做出的努力和尝试。
同样，请提供数据和引用保证严谨。

为避免引起评阅老师判定有凑篇幅之嫌，
请有针对的描述前人研究的不足之处，
做到``有破有立''。
\subsection{}

\section{论文研究内容}

此部分必须详细描述，
必要时可划设小节。
国外学位论文的Introduction章基本仅阐述此内容。
为研究开展的相关工作和实验，
此间遇到何难处及对应的解法。
对论文研究领域不甚了解的评阅老师，
希望从摘要和此小节尽可能的了解最多信息。


\section{论文组织结构}

简明扼要的介绍下各章主旨，版面控制半页内。

\chapter{总结与展望}
\section{技术总结}

本文聚焦于多维度特征融合的数字人建模任务，针对数字人生成的可控性、生成速度、生成质量、时序一致性问题，设计并实现了基于多维度特征融合的生成式数字人解决方案，通过构建数字人基准数据集构建方法，能够从单目视频数据中得到多维度合成图像序列，并构建了基于多维度特征融合的对抗生成网络数字人建模任务范式。为了提高该范式在数字人局部和整体形象上的建模能力，设计了基于人体大模型的损失函数和基于数字人任务的局部位置判别器结构。为了增强该范式的时序一致性，分别提出了基于法线约束的多任务学习方法和基于多帧时序连续性的时序增强方法。本文通过多种实验方案证明了改进方案的正确性和有效性，完成技术链路闭环验证。

最后，总结梳理本文所做工作与成果如下：

1)本文调研了技术研究工作所涉及的科学背景和理论基础。首先分析了生成式的数字人技术的研究意义，应用前景和存在的挑战，并梳理了数字人技术的发展脉络，详细介绍了数字人任务的主要技术框架，为本文基于多特征融合提出的数字人改进方案奠定了理论基础。

2)本文介绍了基于多维度融特征融合的整体科学问题和总体方案。将多维度特征融合分为多维度特征数据集构建和神经网络融合两个阶段，整合集成了面向多维度特征融合的基准数据集构建方案，解决数字人可控性问题；从数据的角度出发，构建的合成图像特征能精确的表征数字人的嘴型、眼部、手部及躯体动作，并利于神经网络模型建模。并以此方法构建了超过30个小时，涵盖新闻播报、演讲、手语表演多个场景的数字人数据集。

3)本文设计实现了一种数字人局部细节和整体形象增强的改进方法。本文基于多维度融合方法提出基于条件对抗生成网络基本架构，实现可实时生成的数字人模型；并进一步设计了基于人体大模型的感知损失和基于局部位置增强的判别器结构，分别从整体形象和局部细节增强数字人建模效果，提升了数字人生成质量，并在多种数字人场景下实验证明了改进的有效性。

4)本文设计与实现了一种基于帧间连续性和法线约束的时序一致性改进。本文分别提出了基于法线约束的多任务学习方法和基于三维分组卷积的帧间连续方法。前者通过跨帧几何一致性，后者通过连续帧条件约束，均有效提升了生成数字人视频的时序一致性。同时结合本文数字人基准数据集构建方法，设计了时序一致性闭环检测方法，用以对生成式数字人视频的时序一致性进行评估分析。

5)本文利用生成式数字人模型构建了实际应用。本文针对客服数字人和节目制作数字人场景，将本文建模的数字人应用于产业化系统当中，进一步阐明了方案的关键技术和交互流程，并阐明系统的测试和优化流程，验证了本文方法的有效性。

\section{未来工作展望}
本文的工作虽然取得了一定的成果，但仍有一些不足之处，未来的研究可以从以下几个方面进行进一步的探索：

1)探索基于预训练的数字人建模方法。本文所提出生成式数字人模型是基于特定数字人身份进行建模。在驱动呈现前需要针对特定人物进行模型训练才能完成建模。模型的泛化能力不足，限制了其在更多的实际场景中的应用；同时对于当前的数字人建模结果，手部仍会出现拟合不好的坏例，如当多维度驱动图像手型未在训练中出现或快速运动的手部帧。因此将模型拓展到能够进行多人物预训练，进一步提高模型的泛化性，使其可以做到零样本或少样本生成是一个很有意义的研究方向。在未来，这可能可以通过进一步探索如 Sapiens\cite{khirodkar2025sapiens} 等大模型去编码人物图像作为输入特征或使用 CLIP\cite{radford2021learning} 编码人物身份来进行实现。

2)进一步提高模型帧间连续性特征融合。本文基于对数字人时序一致性的观察，提出了利用在时序前后的连续帧来建模数字人条件分布。本文仅使用了一个简单的分组三维卷积模块，对该假设进行了验证，成功提高了模型的时序一致性。但是基于模型的时序一致性进一步探索如何更好的结合时序一致性神经网络模块，如利用 Transformer\cite{transformer}、通道维度注意力等模型和机制对以上条件分布进行更高质量的时序一致性建模，是一个有意义的研究方向。

3)人物表面法线的进一步应用。本文成功通过构建法线生成分支以多任务学习的方式在一定程度上重建了人物表面的法线，并直接通过神经网络隐式建模的方式在生成数字人图像时融合了重建的表面法线特征。但对法线贴图而言，其能应用在更多的下游任务当中。如利用法线贴图进行背景重光照，能够进一步提高建模数字人的真实感。因此如何针对模型解码出的人物法线进行进一步的拓展和应用，使其能够更好的结合到当前的模型结构中是非常重要的研究课题。

4)判别器结构的进一步改良。在本文当中，仅探索了使用多判别器融合人物局部特征来提高人物局部的生成效果。而模型的主要判别器结构则依然沿用原始 StyleGAN2 的预测单一真假标签的编码器结构。目前有很多工作探索了如何进一步增强判别器能力，以此提高生成器对于图像分布的学习。如 UNet-GAN\cite{schonfeld2020u} 中提出逐像素判别方法。因此通过提高判别器来进一步提高模型数字人建模的质量，同样是一个有意义的研究方向。

5)数据集的完善与改良。在本文当中，采集并处理的数据集主要针对单目视频场景下的人物演讲、手语表演和新闻播报，主要的数字人类型为全身数字人和半身数字人。此外，本文所构建数据集仅考虑了直接从视频中进行建模的基于 GAN 和 diffusion 架构的单目数字人建模，而不适用于纯粹基于神经辐射场和三位高斯的多视角数字人建模任务。因此为了能够进一步提高数字人数据集的通用性和有效性，除了应该进一步考虑增加更多的场景，如舞蹈动作，多人物对话等，还应增加采录多个视角同步的视频数据或增加采录的单目自旋视频数据以支持基于三维重建和体渲染的数字人建模任务。

6)数字人伦理问题和隐私风险。本文构建的写真生成式数字人模型能够合成逼真的图像，结合音视频融合可以带来真实的视听体验，这在带来技术创新与商业应用机会的同时，也可能被不当利用，产生虚假信息或“深度伪造” （Deepfake） 等问题。此类虚假内容若大规模传播，动摇公众对信息真实性的信任，进而对政治、经济乃至社会稳定产生潜在威胁。因此，本文在实际应用中，已经与企事业单位建立行之有效的内容审核与监测体系。分别对生成前的文本、音频等数据源，生成后的视频内容进行专人专项的审核。此外若后续考虑更广泛的应用，如将生成能力开放给个人用户，将在数字人应用系统中加入水印进行标识，防止模型的恶意使用；最后，针对数据来源的合法性与隐私保护问题，本文针对开源数据集的重处理，遵循其开源协议，仅应用在科研用途中；针对与对应企事业单位，只使用与其合作自采集的数据集。针对自采集的数据集，均取得了对应采集人物的肖像授权。当前相应的模型代码和权重仅与相关合作单位进行闭源使用，确保隐私安全。若后续考虑模型的开源使用，将针对性的使用相关开源协议，防止模型被恶意使用。
